#!env python

import numpy as np
import matplotlib.pyplot as plt
import time
#import pandas as pd
import cPickle as pickle
import os
import codecs
import argparse
import tabulate
import json
import matplotlib.dates as md
import datetime 

fig = plt.figure()
ax = fig.add_subplot(111)
ax.autoscale(enable=True, axis='y', tight=True)

FILETYPE = ".ASC"
FILETYPES = ['.ASC', '.txt']

def autoscale_y(args):
    if args.set_xlim != None:
        xlim = [float(s) for s in args.set_xlim.split()]
        if len(xlim) == 2:
            xmin = xlim[0]
            xmax = xlim[1]

            ymin, ymax = None, None
            for line in ax.lines:
                x = line.get_xdata()
                y = line.get_ydata()
                visible_y = y[(x>=xmin) & (x<=xmax)]
                if len(visible_y):
                    test = np.min(visible_y)
                    if ymin == None or ymin > test:
                        ymin = test
                    test = np.max(visible_y)
                    if ymin == None or ymax < test:
                        ymax = test

            print "autoscale_y: set ylim:", ymin, ymax
            ax.set_ylim((ymin, ymax))

"""
 %% Compute Stress Option 
 E_ti = 130e6/10e5/10e2 % GPa,muStrain,MPa - Warm = Cold
 v_ti = 0.30
 k_plane_ti = E_ti/(1-v_ti^2)
 E_al = 79e6/10e5/10e2
 % Exp. Values
 Nq = length(DB.Current)
 dmax = 13
    for iq = 1 : Nq
      DB.Stress.Coil.C105.Theta{iq} = k_plane_ti*(DB.Coil.C105.Theta{iq}+v_ti*DB.Coil.C105.Zeta{iq})
      DB.Stress.Coil.C106.Theta{iq} = k_plane_ti*(DB.Coil.C106.Theta{iq}+v_ti*DB.Coil.C106.Zeta{iq})
      DB.Stress.Coil.C107.Theta{iq} = k_plane_ti*(DB.Coil.C107.Theta{iq}+v_ti*DB.Coil.C107.Zeta{iq})
      DB.Stress.Coil.C007.Theta{iq} = k_plane_ti*(DB.Coil.C007.Theta{iq}+v_ti*DB.Coil.C007.Zeta{iq})
  
"""
MATERIAL_DATA = { 
		'titanium' : {
			'elastic_modulus':str(130e9/1e6/1e6),
			'poisson_ratio':'0.30'
			},
		'aluminium' : {
			'elastic_modulus':str(79e9/1e6/1e6),
			'poisson_ratio':'0.34'
			},
        	'stainless steel' : {
			'elastic_modulus':str(210e9/1e6/1e6),
			'poisson_ratio':'0.28'
			}

		}

def compute_stress(strain_theta, strain_z, material, axis):
	"""
	stress_z     = E/(1-v**2)*(strain_z     * v * strain_theta)
	stress_theta = E/(1-v**2)*(strain_theta * v * strain_z)
	"""
	E = float(MATERIAL_DATA[material]['elastic_modulus'])
	v = float(MATERIAL_DATA[material]['poisson_ratio'])
	if axis.lower()=='azimuthal': 
		strain_1 = strain_theta
		strain_2 = strain_z
	elif axis.lower()=='longitudinal': 
		strain_1 = strain_z
		strain_2 = strain_theta

	return E/(1.-v**2.)*(strain_1[:] + v * strain_2[:])

def compute_stress_simple(strain, material):
	"""
	stress     = E*strain
	"""
	E = float(MATERIAL_DATA[material]['elastic_modulus'])
	return E * strain[:]


def find_strain_data(mtbop_data, strain_name):
	basename = strain_name[0:-1]
	if strain_name[-1] == 'T': 
		name_theta = strain_name
		name_z = basename + 'Z'
		axis = 'theta'
	elif strain_name[-1] == 'Z':
		name_theta = basename + 'T'
		name_z = strain_name
		axis = 'z'
	else: 
		print "Warning: find_strain_data failed for ", strain_name
	
	if 'SH' in basename: material = 'aluminium'
	elif 'CO' in basename: material = 'titanium'
	elif 'R' in basename: material = 'aluminium'
	else: print "Warning: find_strain_data failed"

	raw_data = mtbop_data['raw_data']
	strain_theta = raw_data[:, find_channel_index(mtbop_data['channel_names'], name_theta)]
	strain_z =     raw_data[:, find_channel_index(mtbop_data['channel_names'], name_z)]

	return strain_theta, strain_z, material, axis

def timeit(func):
	def wrapper(*args, **kwargs):
		time_start = time.time()
		o=func(*args, **kwargs)
		print 'timeit: ', func.__name__, ':{0:0.2f}s'.format(time.time()-time_start)
		return o
	return wrapper

def tol_cols(array):
	return np.array([np.max(col)-np.min(col) for col in array.transpose()])

@timeit
def detect_max_current(mtbop_data):
	raw_data = mtbop_data['raw_data']
	current_array = raw_data[:, find_channel_index(mtbop_data['channel_names'], 'Current')]
	grad_array = np.gradient(current_array)
	qinx = np.argmin(grad_array)
	qinx = np.argmax(current_array)
	mtbop_data['max_current_index'] = qinx
	mtbop_data['max_current'] = current_array[qinx]
	print "mtbop_data['filepath']", mtbop_data['filepath']
	print "mtbop_data['max_current_index']", mtbop_data['max_current_index']
	print "mtbop_data['max_current']", mtbop_data['max_current']

def detect_max_current_grad(mtbop_data, dt=1):
	raw_data = mtbop_data['raw_data']
	current_array = raw_data[:, find_channel_index(mtbop_data['channel_names'], 'Current')]
	grad_array = np.gradient(current_array, dt)
	qinx = np.argmax(grad_array)
	mtbop_data['max_current_grad_index'] = qinx
	mtbop_data['max_current_grad'] = grad_array[qinx]
	print "mtbop_data['filepath']", mtbop_data['filepath']
	print "mtbop_data['max_current_grad_index']", mtbop_data['max_current_grad_index']
	print "mtbop_data['max_current_grad']", mtbop_data['max_current_grad']

def detect_first_values(mtbop_data):
	raw_data = mtbop_data['raw_data']
	initial_values = None
	for i, row in enumerate(raw_data):
		if np.all(filtered_array[i]==0): 
			initial_values = raw_data[i]
			break
	mtbop_data['initial_values'] = initial_values
	

@timeit
def dist_filter(array, abs_dist, filtered_array, turn_on=False):
	"""
	Filter Numpy array column wise. Collect first point of the array and then every point for which the 
	column wise value deviates a distance from the last collected point.
	
	Parameters
	__________
	array : numpy.ndarray
		data array to be filtered
	abs_tol : numpy.ndarray
		column wise distances for the filtering

	Returns
	-------
	filtered_array : numpy.ndarray (bool)
		filtered out elements
	"""
	abs_dist = np.array(abs_dist)
	filtered_array_new = []
	last_mark=None
	for i, row in enumerate(array):
		#if np.any(filtered_array[i] > 0):
			#filtered_row[:] = True
		if last_mark is None or not turn_on:
			last_mark=row
			filtered_row = np.array(np.absolute(row) != np.absolute(row))
		else:
			filtered_row = np.absolute(row-last_mark) < abs_dist
			last_mark = filtered_row*last_mark+(np.logical_not(filtered_row))*row

		filtered_array_new.append(filtered_row)
	return np.array(filtered_array_new)

def filter_indices_after_index(mtbop_data):
	filtered_array = mtbop_data['filtered_array']
	index = mtbop_data['max_current_index']
	filtered_array[index:,:] = 1
	
def index_union(filtered_array, selected_axes_dict):
	inx_sum = np.sum(filtered_array[:,selected_axes_dict], axis=1)
	inx_union = np.where(inx_sum == 0)[0]
	return inx_union

def index_cut(filtered_array, selected_axes_dict):
	inx_product = np.prod(filtered_array[:,selected_axes_dict], axis=1)
	inx_cut = np.where(inx_product == 0)[0]
	return inx_cut

@timeit
def select_mtbop_data(mtbop_data, selected_axes):
	filtered_array = mtbop_data['filtered_array']
	initial_values = mtbop_data['initial_values']
	raw_data = mtbop_data['raw_data']
	inxs = index_union(filtered_array, selected_axes)
	selected_data = raw_data[:,selected_axes][inxs,:]
	if mtbop_data['plot_delta']:
		selected_data[:,:] -= initial_values[[selected_axes]]
	return selected_data

@timeit
def plot_mtbop_data(mtbop_data, args=None):
        if x_axis == 'Current':
            max_current_index = mtbop_data['max_current_index']
	raw_data = mtbop_data['raw_data']
        x_axis_dict = mtbop_data['x_axis']
        y_axis_dict = mtbop_data['y_axis']

        ax_dicts = [x_axis_dict, y_axis_dict]
        for ax_dict in ax_dicts:
            if x_axis == 'Current':
                ax_dict['raw_data'] = raw_data[:max_current_index+1,ax_dict['index']]
            else:
                ax_dict['raw_data'] = raw_data[:,ax_dict['index']]
            if ax_dict['name'] == 'NTP Time':
                ax_dict['raw_data'] =[datetime.datetime.fromtimestamp(stamp) for stamp in ax_dict['raw_data']]
                plt.setp(ax.get_xticklabels(), rotation=25, horizontalalignment='right')
                ax.text(0, -0.2, "Start:" + str(ax_dict['raw_data'][0]), transform = ax.transAxes)
                ax.text(0, -0.25, "End:" + str(ax_dict['raw_data'][-1]), transform = ax.transAxes)
            if ax_dict['name'].lower() == 'current':
                if not args.no_current_squared:
                    ax_dict['raw_data'] = ax_dict['raw_data']**2.
                    if mtbop_data['normalize x'] and ax_dict == x_axis_dict:
                        ax_dict['label'] = '$(I/I_\mathrm{Ult})^2$'
                        ax.axvline(x=0.8, color='black', linestyle='dashed')
                        ax.axvline(x=1.0, color='black', linestyle='dashed')
                        ax.set_xlim((0,1.2))
                        ax.text(0.633, 0.2, 'Nominal', rotation=90, transform = ax.transAxes)
                        ax.text(0.8, 0.2, 'Ultimate', rotation=90, transform = ax.transAxes)
                    else:
                        ax_dict['label'] = ax_dict['name'] + '(' + ax_dict['unit'] + '$^2$)'
                else:
                    ax_dict['label'] = ax_dict['direction'] + ' ' + ax_dict['physical_quantity'] + '(' + ax_dict['unit'] + ')'
            elif ax_dict['name'].lower() == 'data point': 
                ax_dict['label'] = 'Data Point'
            else:
                ax_dict['label'] = ax_dict['direction'] + ' ' + ax_dict['physical_quantity'] + '(' + ax_dict['unit'] + ')'

        if not mtbop_data['common location'] == '':
            y_axis_dict['label'] = mtbop_data['common location'] + ' ' + y_axis_dict['label']

        if mtbop_data['plot delta']:
            y_axis_dict['label'] = '$\Delta$' + y_axis_dict['label']

        if mtbop_data['normalize x'] != None:
            xdata = x_axis_dict['raw_data']/float(mtbop_data['normalize x'])
        else:
            xdata = x_axis_dict['raw_data']

        ydata = y_axis_dict['raw_data']
        ax.set_xlabel(x_axis_dict['label'])
        ax.set_ylabel(y_axis_dict['label'])

        linestyle = '-'
        jump_points = 100

        if len(xdata) <= 10000: jump_points = 1

        if mtbop_data['label type'] == None:
            if 'longname' in y_axis_dict: 
                curve_label=y_axis_dict['longname']
            else: 
                curve_label=y_axis_dict['name']
        elif mtbop_data['label type'] == 'filename':
            curve_label=mtbop_data['filepath'].replace(FILETYPE, '')
            if ('Min' in y_axis_dict['longname'] or 'Max' in y_axis_dict['longname']) and not mtbop_data['show_min_max_labels']:
                print "MIN MAX", mtbop_data['show_min_max_labels']
                curve_label=''
                linestyle = '--'

        if args.fit:
            max_x = np.max(xdata)
            fit_max_x = 1.6 * max_x
            lower_limit = max_x*0.8
            lower_index = np.argmax(xdata>lower_limit)
            fit = np.poly1d(np.polyfit(xdata[lower_index:], ydata[lower_index:], deg=2))

            dindex=len(xdata-lower_index)
            dx = max_x-lower_limit
            xfit_extension = np.linspace(max_x,fit_max_x,dindex/dx*(fit_max_x-max_x))
            xfit = np.concatenate([xdata[lower_index:],xfit_extension])
            ax.plot(xfit[0::jump_points],fit(xfit[0::jump_points]), color=mtbop_data['color'], linestyle='--', label=curve_label+' fit', linewidth=3)
        if mtbop_data['no_markers']:
            curveline, = ax.plot(xdata[0::jump_points],ydata[0::jump_points], color=mtbop_data['color'], linestyle=linestyle, label=curve_label, linewidth=3)
        else:
            curveline, = ax.plot(xdata,ydata, color=mtbop_data['color'], linestyle=linestyle, markevery=mtbop_data['markevery'], label=y_axis_dict['name'])
        if not mtbop_data['label type'] == None and mtbop_data['label type'] == 'filename':
            if 'Min' in y_axis_dict['longname'] or 'Max' in y_axis_dict['longname']:
                curveline.set_dashes([10,20])

@timeit
def plot_selected_list(plot_dict):
        mtbop_data_list = plot_dict['mtbop_data_list']
	for mtbop_data in mtbop_data_list:
		plot_selected(mtbop_data)

def plot_raw_current(mtbop_data):
	raw_data = mtbop_data['raw_data']
	current_index = mtbop_data['current_index']
	ax.plot(raw_data[:, current_index], label=mtbop_data['filepath'])

@timeit
def plot_selected_list_raw_current(mtbop_data_list):
	for mtbop_data in mtbop_data_list:
		plot_raw_current(mtbop_data)
	ax.legend()

def filter_plot_dict(plot_dict):
    if plot_dict['filter_out_str'] != None: 
        filter_words = plot_dict['filter_out_str'].split()
    for channel in plot_dict['channel_dict_list']:
        channel['active'] = True
        if plot_dict['filter_out_str'] != None: 
            if any(word in channel['name'] for word in filter_words):
                channel['active'] = False
                print channel['name'], "filtered", "|", filter_words

def get_cryocorrection(head):
    print "Getting cryocorrection factor",
    cryocorrection = None
    for line in head:
        if 'CHANNELS:' in line:
            try:
                cryocorrection = float(line.split('cryocorrection')[1].split('=')[1])
                break
            except:
                print "...not found."
                pass

    return cryocorrection

def replace_raw_data_channels(mtbop_data):
    print "Trying to replace channels..."
    try:
        raw_data = mtbop_data['raw_data']
        channel_names = mtbop_data['channel_names']
        for replacement in mtbop_data['channel_replacements']['index_list']:
            replacer_ch = replacement[0]
            replaced_ch = replacement[1]
            raw_data[:,replaced_ch] = raw_data[:,replacer_ch]
            print "channel replacement:", channel_names[replacer_ch], "->", channel_names[replaced_ch]
        print "done."
    except:
        print "Channel replacement not done."
    print "If you want to modify the channel replacements, you need to do it in the data file (AND RERUN THE PICKLE)."

def get_channel_replacements(mtbop_data, head, channel_names):
    mtbop_data['channel_replacements'] = {}
    chrep = mtbop_data['channel_replacements'] 
    print "Getting replacement channels data",
    replacements_list=None
    for line in head:
        if 'channel_replacements:' in line:
            try:
                print line.split('channel_replacements:')[1]
                chrep['string_list'] = [line.rstrip().split(':')[1].split(',')]
                chrep['index_list'] = [[channel_names.index(l) for l in s.strip().split('->')] for s in line.rstrip().split(':')[1].split(',')]
                print "Corresponds to channel numbers:", chrep['index_list'] 
                return
                break
            except:
                print "...not found."
                pass
            
    print "...not found."
    return replacements_list

@timeit
def load_mtbop_data(filepath, override_pickle=False, header_lines=38, args=None):
	"""
	Loads mtbop data from txt file.
	
	Parameters
	__________
	filepath : string
		path of the mtbop data file
	header_lines : int
		number of header lines in mtbop file
	
	Returns
	-------
	mtbop_data : json?
		{
		 'filepath' = string,
		 channel_names = [string, .., string],
		 channel_units = [string, .., string],
		 raw_data = numpy.ndarray}
	"""
	basename = os.path.splitext(filepath)[0]
	pickle_path = basename + '.pickle'
	if os.path.isfile(pickle_path) and not override_pickle:
		print "Found a pickle:", pickle_path, "for", filepath, "using that instead."
		return cpickle_load(pickle_path)

	mtbop_data = {}
	with codecs.open(basename + FILETYPE) as f:
		head = [next(f).decode('utf-8', 'ignore') for x in xrange(header_lines)]
	channel_names = head[8].strip('\r\n').split('\t')
        get_channel_replacements(mtbop_data, head, channel_names)

	channel_names = [name.split()[0].replace('_cryo','') for name in channel_names]
	channel_units = head[9].strip('\r\n').split('\t')
	#raw_data_df = pd.read_csv(filepath, sep = '\t', skiprows=header_lines, names=channel_names)

	with codecs.open(filepath) as f:
		raw_data = np.loadtxt(f, skiprows=header_lines)

	mtbop_data['filepath'] = filepath
	mtbop_data['channel_units'] = channel_units
        mtbop_data['channel_dict_list'] = create_channel_dict_list(channel_names, channel_units)
	mtbop_data['channel_names'] = [channel_dict['name'] for channel_dict in mtbop_data['channel_dict_list']]
	#mtbop_data['raw_data_df'] = raw_data_df
	#mtbop_data['raw_data'] = raw_data_df.values
	mtbop_data['raw_data'] = raw_data
        signal_compensation(mtbop_data)
	mtbop_data['cryocorrection'] = get_cryocorrection(head)
        if mtbop_data['cryocorrection'] != None: signal_cryocorrection(mtbop_data)
        reconstruct_ntp_time(mtbop_data)
        
        add_column_to_mtbop_raw_data(mtbop_data, np.arange(np.size(mtbop_data['raw_data'][:,1]))+1, 'Data Point')
        data_point_channel_dict = {}
        data_point_channel_dict['name'] = 'Data Point'
        data_point_channel_dict['longname'] = 'Data Point'
        data_point_channel_dict['sensor type'] = ''
        data_point_channel_dict['location'] = ''
        data_point_channel_dict['thermal compensator'] = ''
        data_point_channel_dict['direction'] = '' 
        data_point_channel_dict['physical_quantity'] = ''
        data_point_channel_dict['longitudinal location'] = ''
        data_point_channel_dict['unit'] = ''
        mtbop_data['channel_dict_list'].append(data_point_channel_dict)

        #convert_units_to_umum(mtbop_data)
	#mtbop_data['filtered_array'] = np.zeros(np.shape(raw_data))
	#mtbop_data['channel_tolerance'] = tol_cols(mtbop_data['raw_data'])
	#detect_max_current(mtbop_data)

	#filter_indices_after_index(mtbop_data)
	#detect_first_values(mtbop_data)
	
	cpickle_dump(mtbop_data, pickle_path)
	return mtbop_data

def signal_compensation(mtbop_data):
    for compensator_index, compensator_dict in enumerate(mtbop_data['channel_dict_list']):
        if compensator_dict['thermal compensator'] == 'compensator':
            search_terms = compensator_dict['longname'].split()
            try:
                search_terms.remove('compensator')
            except:
                pass
            print search_terms
            for compensated_index, compensated_dict in enumerate(mtbop_data['channel_dict_list']):
                compensated_dict['compensation done'] = False
                if all(search_term in compensated_dict['name'] for search_term in search_terms) and compensated_dict['thermal compensator'] == '':
                    print "Thermal compensator (" + compensator_dict['name'] + ") found for:", compensated_dict['name']
                    mtbop_data['raw_data'][:,compensated_index] -= mtbop_data['raw_data'][:,compensator_index]
                    compensated_dict['compensation done']=True
                    print "Compensation done."

def signal_cryocorrection(mtbop_data):
    print "cryocorrection", mtbop_data['cryocorrection']
    for chind, channel_dict in enumerate(mtbop_data['channel_dict_list']):
        if 'physical_quantity' in channel_dict and channel_dict['physical_quantity'] == 'Strain':
            print "cryo correction for: ", channel_dict['name']
            mtbop_data['raw_data'][:, chind] *= mtbop_data['cryocorrection']

def reconstruct_ntp_time(mtbop_data):
    print "Check for reconstructing NTP Time"
    raw_data = mtbop_data['raw_data']
    nof_reconstructs = 0
    nof_failed = 0
    for chind, channel_dict in enumerate(mtbop_data['channel_dict_list']):
        if channel_dict['name'] == 'NTP Time':
            for row, data_point in enumerate(raw_data[:,chind]):
                if data_point == 0:
                    try:
                        raw_data[row,chind] = int(raw_data[row-1,chind] + raw_data[row-1,chind] - raw_data[row-2,chind])
                        print "Row", row, "reconstructed", "new value:", raw_data[row,chind] 
                        nof_reconstructs += 1
                    except:
                        print "Reconstruct failed for row", row
                        nof_failed += 1
    print "Number of reconstructed NTP time values", nof_reconstructs
    if nof_failed != 0:
        print "Number of failed NTP time reconstructs", nof_failed

def convert_units_to_umum(mtbop_data):
    raw_data = mtbop_data['raw_data']
    for i, channel_dict in enumerate(mtbop_data['channel_dict_list']):
        if channel_dict['unit'] == 'um/m':
            #raw_data[:,i] *= 1e-6
            channel_dict['unit'] = 'um/um'

def load_mtbop_list(filepath_list, override_pickle=False, header_lines=38, args=None):
	mtbop_data_list = []
	for filepath in filepath_list:
		mtbop_data = load_mtbop_data(filepath, override_pickle, args=args)
                if not args == None:
                    if args.replace_channels:
                        replace_raw_data_channels(mtbop_data)
                    if args.print_max_current: 
                        detect_max_current(mtbop_data)
		mtbop_data_list.append(mtbop_data)
	return mtbop_data_list

def find_channel_index(channel_names, channel_name):
	return channel_names.index(channel_name)

def find_axes(mtbop_data):
	channel_names = mtbop_data['channel_names']
	channel_units = mtbop_data['channel_units']
	mtbop_data['current_index'] = channel_names.index('Current')
	axes_list = []
	for pair in name_pairs:
		if pair[0] in channel_names and pair[1] in channel_names: 
			first = channel_names.index(pair[0])
			second = channel_names.index(pair[1])
			axes = {'selected_axes': (first,second)}
			if pair[0].lower() == 'current':
				axes['0 scaling']='current'
			else: 
				axes['0 scaling']=''
			if pair[1].lower() == 'current':
				axes['1 scaling']='current'
			else: 
				axes['1 scaling']=''
			axes['0 name'] = pair[0]
			axes['1 name'] = pair[1]
			axes['0 unit'] = channel_units[first]
			#axes['1 unit'] = channel_units[second]
			axes_list.append(axes)
	return axes_list

@timeit
def test_pandas_load_data(filepath, header_lines=38):
	raw_data = pd.read_csv(filepath, sep = '\t', skiprows=header_lines,usecols=range(21))
	print raw_data.values[2]

@timeit
def test_numpy_load_data(filepath, header_lines=38):
	raw_data = np.loadtxt(filepath, skiprows=header_lines)
	print raw_data[2]

def test_load_data():
	filepath = 'Data/test/01QuenchDC_161013_16236.txt'
	test_pandas_load_data(filepath)
	test_numpy_load_data(filepath)

@timeit
def test_cpickle_dump():
	filepath = 'Data/test/01QuenchDC_161013_16236.txt'
	mtbop_data = load_mtbop_data(filepath)
	with open('test.pickle', 'wb') as handle:
		pickle.dump(mtbop_data, handle, protocol=pickle.HIGHEST_PROTOCOL)
@timeit
def cpickle_dump(data, pickle_path):
	with open(pickle_path, 'wb') as handle:
		pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)
	
@timeit
def cpickle_load(pickle_path):
	with open(pickle_path, 'rb') as handle:
		mtbop_data = pickle.load(handle)
	return mtbop_data

def print_max_current(mtbop_data):
    print "!!!!! ---------------------------MAX CURRENT--------------------------!!!!!"
    print mtbop_data['filepath'], mtbop_data['max_current'],
    print "!!!!! ----------------------------------------------------------------!!!!!"

def make_info_table(mtbop_data_list):
	info_table = [['File path', 'Max Current']]
	for mtbop_data in mtbop_data_list:
		info_table.append([mtbop_data['filepath'], mtbop_data['max_current']])
	return info_table

def test_plot_selected():
	#use_dist_filter = False
	#nof_points = 1e4
	filepath = 'Data/test/01QuenchDC_161013_16236.txt'
	#filepath = 'Data/test/02QuenchDC_161013_18055.txt'
	selected_channel_names = [('Current','CO105Z_cryo'), ('Current','CO105T_cryo')]
	#selected_channel_names = [('Current','CO105T_cryo')]
	plot_delta = True
	#selected_channel_names = [('CO105T_cryo','Current')]
	#selected_channel_names = [('Current','SHTT_cryo')]
	#selected_channel_names = [('CO105T_cryo','SHTT_cryo')]

	mtbop_data = load_mtbop_data(filepath)
	mtbop_data['selected_channel_names'] = selected_channel_names
	mtbop_data['selected_axes_dict'] = find_axes(mtbop_data)
	mtbop_data['plot_delta'] = plot_delta

	#mtbop_data['filter_approx_points'] = nof_points
	#filtered_array = dist_filter(raw_data, tol/nof_points, filtered_array, turn_on=use_dist_filter)

	plot_selected(mtbop_data)

	plt.show()

def test_plot_selected_list():
	#datadir = 'Data/MQXFS4' 
	#datadir = 'Data/HCMQXFS004-CR000001' 
	#filepath_list = [datadir + '/' + f for f in os.listdir(datadir) if FILETYPE in f]
	max_current_low_limit = 15
	
	#filepath_list = ['Data/test/01QuenchDC_161013_16236.txt', 
		         #'Data/test/02QuenchDC_161013_18055.txt']
	#selected_channel_names = [('CO105T_cryo','Current')]

	filepath_list = ['Data/HCMQXFS004-CR000001/180704_12_15_23_Quench.txt', 
                         'Data/HCMQXFS004-CR000001/180709_14_40_50_Quench.txt', 
                         'Data/HCMQXFS004-CR000001/180730_18_07_11_Quench.txt']

	print filepath_list

	mtbop_data_list = []
	selected_channel_names = [('Current','CO109T')]
	plot_delta = True
	for filepath in filepath_list:
		mtbop_data = load_mtbop_data(filepath)
		if mtbop_data['max_current'] > max_current_low_limit:
			mtbop_data_list.append(mtbop_data)
			mtbop_data = mtbop_data_list[-1]
			mtbop_data['selected_channel_names'] = selected_channel_names
			mtbop_data['selected_axes_dict'] = find_axes(mtbop_data)
			mtbop_data['plot_delta'] = plot_delta
			print_max_current(mtbop_data)

	plot_selected_list(mtbop_data_list)
	#plot_selected_list_raw_current(mtbop_data_list)

	plt.show()

def plot_selected_files(filepath_list, selected_channel_names):
	max_current_low_limit = 15

	mtbop_data_list = []
	plot_delta = True
	for filepath in filepath_list:
		mtbop_data = load_mtbop_data(filepath)
		if mtbop_data['max_current'] > max_current_low_limit:
			mtbop_data_list.append(mtbop_data)
			mtbop_data = mtbop_data_list[-1]
			mtbop_data['selected_channel_names'] = selected_channel_names
			mtbop_data['selected_axes_dict'] = find_axes(mtbop_data)
			mtbop_data['plot_delta'] = plot_delta
			print_max_current(mtbop_data)

	plot_selected_list(mtbop_data_list)
	#plot_selected_list_raw_current(mtbop_data_list)

	plt.show()

def testing():
	test_plot_selected()
	#test_plot_selected_list()
	#test_load_data()
	#test_cpickle_dump()
	#cpickle_load('test.pickle')


def print_mtbop_info(filepaths):
	info_table = make_info_table(mtbop_data_list)
	print tabulate.tabulate(info_table, headers="firstrow")

def find_channel_names(mtbop_data_list):
	channel_names_list = []
	for mtbop_data in mtbop_data_list:
		channel_names_list += mtbop_data['channel_names']
	return list(set(channel_names_list))
	
def find_files(paths):
	filepaths=[]
	for path in paths:
		if os.path.isdir(path):
			filepaths += [path + '/' + f for f in os.listdir(path) if FILETYPE in f]
		elif os.path.isfile(path) and FILETYPE in path:
			filepaths.append(path)
	return filepaths

def create_channel_data(mtbop_data_list):
    channel_dict_list = get_channel_data(mtbop_data_list)
    print "Writing channels.json"
    with open('channels.json', 'w') as outfile:
        json.dump(channel_dict_list, outfile, indent=4)
    return channel_dict_list
    #return create_channel_data_original(mtbop_data_list)
    #return create_channel_data_fuji(mtbop_data_list)

def create_channel_dict_list(channel_names, channel_units):
        channel_dict_list = []
	for i, channel_name in enumerate(channel_names):
		channel_dict_list.append({})
		channel_dict = channel_dict_list[-1]

                channel_dict['signal'] = 'raw'

                print channel_name
                if '_Stress' in channel_name:
                    channel_name = channel_name.replace('_Stress','')
                    channel_dict['signal'] = 'stress post computation'
                if 'Strain_' in channel_name:
                    channel_name = channel_name.replace('Strain_','')
                if '_cryo' in channel_name:
                    channel_name = channel_name.replace('_cryo','')


                if '_inter' in channel_name:
                    channel_dict['interpolation'] = True
                    channel_name = channel_name.split('_interpolation')[0]
                elif '_Inter' in channel_name:
                    channel_dict['interpolation'] = True
                    channel_name = channel_name.split('_Interpolation')[0]

		channel_dict['name'] = channel_name
                channel_dict['sensor type'] = ''
                channel_dict['location'] = ''
                channel_dict['unit'] = channel_units[i]
                channel_dict['thermal compensator'] = ''
                channel_dict['direction'] = '' 
                channel_dict['physical_quantity'] = ''

                channel_dict['longitudinal location'] = ''
                if '_LE' in channel_name:
                    channel_dict['longitudinal location'] = 'LE'
                elif '_CE' in channel_name or '_MI' in channel_name:
                    channel_dict['longitudinal location'] = 'CE'
                elif '_RE' in channel_name:
                    channel_dict['longitudinal location'] = 'RE'

                if '_comp' in channel_name.lower(): 
                    channel_dict['thermal compensator'] = 'compensator'

                if 'SG_' == channel_name[0:3]:
                    channel_name = channel_name.replace('SG_','')
                    channel_dict['sensor type'] = 'resistive'

                if channel_name == 'Current':
                    channel_dict['physical_quantity'] = 'Current'
                elif channel_name == 'Time':
                    channel_dict['physical_quantity'] = 'Time'
                elif 'NTP' in channel_name and 'TIME' in channel_name:
                    channel_dict['physical_quantity'] = 'Time'
                    channel_dict['sensor type'] = 'NTP'
                    channel_dict['longname'] = 'NTP Time'
                    channel_dict['name'] = 'NTP Time'
                elif 'pressure' in channel_name.lower():
                    channel_dict['unit'] = 'Bar'
                    channel_dict['physical_quantity'] = 'Pressure'
                    if 'Rod' in channel_name:
                        channel_dict['name'] = 'Piston Pressure'
                        channel_dict['longname'] = 'Piston Pressure'
                    elif 'bladder' in channel_name.lower():
                        channel_dict['name'] = 'Bladder Pressure'
                        channel_dict['longname'] = 'Bladder Pressure'
                else:
                    if channel_name[0:2] == 'SH':
                            shell_location = ''
                            if channel_name[2] == 'R': shell_location = 'Right'
                            elif channel_name[2] == 'L': shell_location = 'Left'
                            elif channel_name[2] == 'T': shell_location = 'Top'
                            elif channel_name[2] == 'B': shell_location = 'Bottom'
                            if channel_name[3] == 'Z': channel_dict['direction'] = 'Longitudinal'
                            elif channel_name[3] == 'T': channel_dict['direction'] = 'Azimuthal'
                            channel_dict['location'] = 'Shell ' + shell_location
                            channel_dict['physical_quantity'] = 'Strain'
                            channel_dict['material'] = 'aluminium'
                    elif channel_name[0] == 'R': 
                            channel_dict['location'] = 'Rod ' + channel_name[1]
                            channel_dict['physical_quantity'] = 'Strain'
                            channel_dict['material'] = 'aluminium'
                    elif channel_name[0:2] == 'CO':
                            channel_dict['location'] = 'Coil ' + channel_name[2:5]
                            channel_dict['physical_quantity'] = 'Strain'
                            channel_dict['material'] = 'titanium'
                    elif channel_name == 'Current':
                            channel_dict['physical_quantity'] = 'Current'
                            channel_dict['location'] = 'None'
                    else:
                            channel_dict['location'] = channel_name 
                            channel_dict['physical_quantity'] = 'None'

                    if channel_dict['sensor type'] == '':
                        if '_SG' in channel_name in channel_name:
                                channel_dict['sensor type'] = 'resistive'
                        elif '_FBG' in channel_name:
                                channel_dict['sensor type'] = 'optical'
                        else: channel_dict['sensor type'] = ''
                    if '_Z' in channel_name or channel_name[-1] == 'Z':
                            channel_dict['direction'] =  'Longitudinal'
                    elif '_T' in channel_name or channel_name[-1] == 'T':
                            channel_dict['direction'] = 'Azimuthal'

                    if channel_dict['signal'] == 'stress post computation':
                        channel_dict['physical_quantity'] = 'Stress'
                        channel_dict['unit'] = 'MPa'

                    channel_dict['longname'] = get_channel_longname(channel_dict)
                    channel_dict['name'] = get_channel_longname(channel_dict)

	return channel_dict_list

def get_channel_data(mtbop_data_list):
    channel_names = find_channel_names(mtbop_data_list)
    channel_dict_list = []
    for mtbop_data in mtbop_data_list:
        channel_dict_list += mtbop_data['channel_dict_list']
    channel_dict_list_names = [ch_dict['name'] for ch_dict in channel_dict_list]
    channel_names_indices_in_list = [channel_dict_list_names.index(channel_name) for channel_name in channel_names]
    channel_dict_list_out=[]
    channel_dict_list_out = [channel_dict_list[ind] for ind in channel_names_indices_in_list]

    return channel_dict_list_out

def create_channel_data_original(mtbop_data_list):
	channel_names = find_channel_names(mtbop_data_list)
	channel_dict_list = [] 
	for channel_name in channel_names:
		channel_dict_list.append({})
		channel_dict = channel_dict_list[-1]
		channel_dict['name'] = channel_name
		if channel_name[0:2] == 'SH':
			shell_location = ''
			if channel_name[2] == 'R': shell_location = 'Right'
			elif channel_name[2] == 'L': shell_location = 'Left'
			elif channel_name[2] == 'T': shell_location = 'Top'
			elif channel_name[2] == 'B': shell_location = 'Bottom'
			channel_dict['location'] = 'Shell ' + shell_location
			channel_dict['physical_quantity'] = 'Strain'
			channel_dict['unit'] = 'um/um'
                        channel_dict['material'] = 'aluminium'
		elif channel_name[0] == 'R': 
			channel_dict['location'] = 'Rod ' + channel_name[1]
			channel_dict['physical_quantity'] = 'Strain'
			channel_dict['unit'] = 'um/um'
                        channel_dict['material'] = 'aluminium'
		elif channel_name[0:2] == 'CO':
			channel_dict['location'] = 'Coil ' + channel_name[2:5]
			channel_dict['physical_quantity'] = 'Strain'
			channel_dict['unit'] = 'um/um'
                        channel_dict['material'] = 'titanium'
		elif channel_name == 'Current':
			channel_dict['physical_quantity'] = 'Current'
			channel_dict['location'] = 'None'
			channel_dict['unit'] = 'A'
		else:
			channel_dict['location'] = channel_name 
			channel_dict['physical_quantity'] = 'None'
			channel_dict['unit'] = 'None'
                if '_SG' in channel_name:
                        channel_dict['sensor type'] = 'resistive'
                elif '_FBG' in channel_name:
                        channel_dict['sensor type'] = 'optical'
                else: channel_dict['sensor type'] = ''
                if '_Z' in channel_name or channel_name[-1] == 'Z':
			channel_dict['direction'] =  'Longitudinal'
                elif '_T' in channel_name or channel_name[-1] == 'T':
			channel_dict['direction'] = 'Azimuthal'
		else:
			channel_dict['direction'] = 'None'

                channel_dict['longname'] = get_channel_longname(channel_dict)
                channel_dict['name'] = get_channel_longname(channel_dict)

	print "Writing channels.json"
	with open('channels.json', 'w') as outfile:
		json.dump(channel_dict_list, outfile, indent=4)
	
	return channel_dict_list

def create_channel_data_fuji(mtbop_data_list):
	channel_names = find_channel_names(mtbop_data_list)
	channel_dict_list = [] 
	for channel_name in channel_names:
		channel_dict_list.append({})
		channel_dict = channel_dict_list[-1]
		channel_dict['name'] = channel_name
		if 'Strain_' in channel_name:
			channel_dict['physical_quantity'] = 'Strain'
			channel_dict['unit'] = 'um/um'
                else:
			channel_dict['physical_quantity'] = 'Datetime'
                        channel_dict['unit'] = 'HH:MM:SS'
                if '_LE_' in channel_name:
			channel_dict['location'] = 'Lead End'
                elif '_CE_':
			channel_dict['location'] = 'Center'
                elif '_RE_':
			channel_dict['location'] = 'Return End'
                else: 
			channel_dict['location'] = ''
                if '_T' in channel_name[-2:-1]:
                        channel_dict['direction'] = 'Azimuthal'
                elif '_Z' in channel_name:
                        channel_dict['direction'] = 'Longitudinal'
                else:
                        channel_dict['direction'] = ''

                channel_dict['longname'] = get_channel_longname(channel_dict)
                channel_dict['longname'] = get_channel_name(channel_dict)

	print "Writing channels.json"
	with open('channels.json', 'w') as outfile:
		json.dump(channel_dict_list, outfile, indent=4)
	
	return channel_dict_list

def add_stress_channel_data(plot_dict):
    added_dicts = []
    #location_dict = {}
    channel_dict_list = plot_dict['channel_dict_list']
    for channel_dict in channel_dict_list:
        if channel_dict['physical_quantity'] == 'Strain':
            added_dicts.append(dict(channel_dict))
            added_dict = added_dicts[-1]
            added_dict['physical_quantity'] = 'Stress'
            added_dict['longname'] = get_channel_longname(added_dict)
            added_dict['name'] = added_dict['longname'] 
            added_dict['material'] = channel_dict['material'] 
            added_dict['unit'] = 'MPa'
    #        if not added_dict['location'] in location_dict:
    #            location_dict[added_dict['location']] = {}
    #            if not added_

    plot_dict['channel_dict_list'] += added_dicts

def get_average_name(y_axis_names):
    av_set_list = [set(y_axis_name.split()) for y_axis_name in y_axis_names]
    common_words = list(set.intersection(*av_set_list))
    first_name = y_axis_names[0].split()
    average_name = ' '.join([word for word in first_name if word in common_words])
    return average_name

def match_words_channel_dicts(wordlist, channel_dict_list):
    matched_dicts = []
    matched_names = []
    for cdict in channel_dict_list:
        if cdict['active']:
            if all(word in cdict['name'] for word in wordlist):
                matched_dicts.append(cdict)
                matched_names.append(cdict['name'])

    return matched_dicts, matched_names

def add_average_channel_data(plot_dict, y_axis_names):
    print "Average names:", y_axis_names
    wordlist = y_axis_names[0].split()
    print "wordlist: ", wordlist
    matched_dicts, matched_names = match_words_channel_dicts(wordlist, plot_dict['channel_dict_list'])
    print "matched_names:", matched_names
    
    plot_dict['matched_names'] = matched_names
    added_dicts = []
    #location_dict = {}
    channel_dict_list = matched_dicts
    example_dict = channel_dict_list[0]
    average_name = y_axis_names[0]

    for suffix in [' Min', ' Max', ' Avg']:
        added_dicts.append(dict(example_dict))
        added_dict = added_dicts[-1]
        added_dict['name'] = average_name + suffix
        added_dict['longname'] = added_dict['name']

    plot_dict['channel_dict_list'] += added_dicts

    plot_dict['channel_name_dict'] = create_channel_name_dict(plot_dict['channel_dict_list'])
    return average_name, matched_names
    #        if not added_dict['location'] in location_dict:
    #            location_dict[added_dict['location']] = {}
    #            if not added_


def get_channel_longname(channel_dict):
    longname = channel_dict['location']
    if not channel_dict['direction'] == '': longname += ' ' + channel_dict['direction']
    if not channel_dict['physical_quantity'] == '': longname += ' ' + channel_dict['physical_quantity']
    if not channel_dict['sensor type'] == '': longname += ' ' + channel_dict['sensor type']
    if not channel_dict['thermal compensator'] == '': longname += ' ' + channel_dict['thermal compensator']
    if not channel_dict['longitudinal location'] == '': longname += ' ' + channel_dict['longitudinal location']

    return longname

def get_channel_name(channel_dict):
    return channel_dict['location'] + ' ' + channel_dict['direction'] + ' ' + channel_dict['physical_quantity']

def find_channels_from_dict(channel_dict_list, location, physical_quantity, direction):
	channel_dict_sub = []
	for channel_dict in channel_dict_list: 
		if channel_dict['location'] == location and channel_dict['physical_quantity'] == physical_quantity and channel_dict['direction'] == direction:
			   channel_dict_sub.append(channel_dict)
	return channel_dict_sub


def read_channels_json(channels_json_file_path):
	with open(channels_json_file_path, 'r') as f:
		data_json = json.load(f)
	return data_json

def double_array_columns_with_zeros(array):
	size1, size2 = np.shape(array)
	new_array = np.zeros((size1, 2*size2))
	new_array[:,0:size2] = array
	return new_array

def double_vector_with_zeros(vector):
	size = np.size(vector)
	new_vector = np.zeros(2*size)
	new_vector[0:size] = vector
	vector = new_vector

def search_channel_dict(channel_dict_list, location, direction, physical_quantity, longitudinal_location, sensor_type):
    for channel_dict in channel_dict_list:
        if channel_dict['sensor type'] == sensor_type and channel_dict['location'].lower() == location.lower() and channel_dict['longitudinal location'].lower() == longitudinal_location.lower() and channel_dict['direction'].lower() == direction.lower() and channel_dict['physical_quantity'].lower() == physical_quantity.lower(): return channel_dict
    return None

def add_stress_data_to_dicts(channel_dict_list):
    print "Add strain dicts to stress channel dictionaries:"
    for channel_dict in channel_dict_list:
        if channel_dict['physical_quantity'].lower() == 'stress':
            strain_longitudinal = search_channel_dict(channel_dict_list, channel_dict['location'], 'longitudinal', 'strain', channel_dict['longitudinal location'], channel_dict['sensor type'])
            strain_azimuthal = search_channel_dict(channel_dict_list, channel_dict['location'], 'azimuthal', 'strain', channel_dict['longitudinal location'], channel_dict['sensor type'])
            channel_dict['strain'] = {}
            channel_dict['strain']['longitudinal'] = strain_longitudinal
            channel_dict['strain']['azimuthal'] = strain_azimuthal

def get_raw_data_by_name(mtbop_data, channel_name):
    if channel_name in mtbop_data['channel_names']:
        index = mtbop_data['channel_names'].index(channel_name) 
        return mtbop_data['raw_data'][:,index]

def add_column_to_mtbop_raw_data(mtbop_data, data, name):
    mtbop_data['channel_names'].append(name)
    mtbop_data['raw_data'] = np.c_[mtbop_data['raw_data'], data]

def compute_stresses(plot_dict):
    mtbop_data_list = plot_dict['mtbop_data_list'] 
    channel_dict_list = plot_dict['channel_dict_list']
    add_stress_data_to_dicts(channel_dict_list)
    for mtbop_data in mtbop_data_list:
	print "Computing stresses for:", mtbop_data['filepath']
        for channel_dict in channel_dict_list:
            if channel_dict['physical_quantity'].lower() == 'stress':
                raw_data = mtbop_data['raw_data']
                material = channel_dict['material']
                azimuthal_dict = channel_dict['strain']['azimuthal']
                longitudinal_dict = channel_dict['strain']['longitudinal']

                try:
                    if not azimuthal_dict == None:
                            azimuthal_strain = get_raw_data_by_name(mtbop_data, azimuthal_dict['name']) 
                            longitudinal_strain = get_raw_data_by_name(mtbop_data, longitudinal_dict['name']) 
                            stress_data = compute_stress(azimuthal_strain, longitudinal_strain, material, channel_dict['direction'])
                    else:
                        longitudinal_strain = get_raw_data_by_name(mtbop_data, longitudinal_dict['name']) 
                        stress_data = compute_stress_simple(longitudinal_strain, material)
                    add_column_to_mtbop_raw_data(mtbop_data, stress_data, channel_dict['name'])
                except:
                    pass
    return

#	raw_data = mtbop_data['raw_data']
#	size1, size2 = np.shape(raw_data)
#	mtbop_data['raw_data'] = double_array_columns_with_zeros(raw_data)
#	raw_data = mtbop_data['raw_data']
#
#	mtbop_data['filtered_array'] = double_array_columns_with_zeros(mtbop_data['filtered_array'])
#	print np.shape(mtbop_data['initial_values'])
#	mtbop_data['initial_values'] = double_vector_with_zeros(mtbop_data['initial_values'])
#	print np.shape(mtbop_data['initial_values'])
#
#	locations = list(set([channel_dict['location'] for channel_dict in channel_dicts]))
#	computed_dicts = []
#
#	channel_count = 0
#	for location in locations:
#		if not location == 'None':
#			print "location: ", location
#			azimuthal_dicts = find_channels_from_dict(channel_dicts, location, 'Strain', 'Azimuthal')
#			if len(azimuthal_dicts) == 1: azimuthal_dict = azimuthal_dicts[0]
#			else: azimuthal_dict = None
#			longitudinal_dicts = find_channels_from_dict(channel_dicts, location, 'Strain', 'Longitudinal')
#			if len(longitudinal_dicts) == 1: longitudinal_dict = longitudinal_dicts[0]
#			else: 
#				print "Error: longitudinal of the location was not found!"
#				exit()
#
#			longitudinal_name = longitudinal_dict['name']
#			longitudinal_index = find_channel_index(mtbop_data['channel_names'], longitudinal_name)
#
#			if 'Shell' in longitudinal_dict['location']: material = 'aluminium'
#			elif 'Rod' in longitudinal_dict['location']: material = 'aluminium'
#			elif 'Coil' in longitudinal_dict['location']: material = 'titanium'
#
#			print channel_count
#
#			if not azimuthal_dict == None:
#				azimuthal_name = azimuthal_dict['name']
#				azimuthal_index = find_channel_index(mtbop_data['channel_names'], azimuthal_name)
#				raw_data[:, size2+channel_count] = compute_stress(raw_data[:,azimuthal_index], raw_data[:,longitudinal_index], material, 'theta')
#				channel_count += 1
#				computed_dicts.append({})
#				channel_name = location + ' Azimuthal Stress'
#				computed_dicts[-1]['name'] = channel_name
#				computed_dicts[-1]['location'] = location
#				computed_dicts[-1]['physical_quantity'] = 'Stress'
#				computed_dicts[-1]['direction'] = 'Azimuthal'
#				mtbop_data['channel_names'].append(channel_name)
#
#				raw_data[:, size2+channel_count] = compute_stress(raw_data[:,azimuthal_index], raw_data[:,longitudinal_index], material, 'z')
#				channel_count += 1
#				computed_dicts.append({})
#				channel_name = location + ' Longitudinal Stress'
#				computed_dicts[-1]['name'] = channel_name
#				computed_dicts[-1]['location'] = location
#				computed_dicts[-1]['physical_quantity'] = 'Stress'
#				computed_dicts[-1]['direction'] = 'Longitudinal'
#				mtbop_data['channel_names'].append(channel_name)
#			else:
#				raw_data[:, size2+channel_count] = compute_stress_simple(raw_data[:,longitudinal_index], material)
#				channel_count += 1
#				computed_dicts.append({})
#				channel_name = location + ' Longitudinal Stress'
#				computed_dicts[-1]['name'] = channel_name
#				computed_dicts[-1]['location'] = location
#				computed_dicts[-1]['physical_quantity'] = 'Stress'
#				computed_dicts[-1]['direction'] = 'Longitudinal'
#				mtbop_data['channel_names'].append(channel_name)

def create_channel_name_dict(channel_dict_list):
	channel_name_dict = {}
	for channel_dict in channel_dict_list:
		channel_name_dict[channel_dict['name']]=channel_dict
	return channel_name_dict

def create_plot_dict(paths, channels_json, plot_stress=False, args=None):
	plot_dict = {}
	plot_dict['paths'] = paths
	plot_dict['filepaths'] = find_files(paths)
	plot_dict['mtbop_data_list'] = load_mtbop_list(plot_dict['filepaths'], override_pickle, args=args)
	plot_dict['plot_stress'] = plot_stress

	if not channels_json == None: 
		plot_dict['channel_dict_list'] = read_channels_json(channels_json)
	else:
		plot_dict['channel_dict_list'] = create_channel_data(plot_dict['mtbop_data_list'])

        if plot_stress:
            add_stress_channel_data(plot_dict)
            compute_stresses(plot_dict)

	plot_dict['channel_name_dict'] = create_channel_name_dict(plot_dict['channel_dict_list'])

	return plot_dict 

def get_selected_channel_names(plot_dict):
    plot_dict['selected_channel_names'] = [channel_dict['name'] for channel_dict in plot_dict['channel_dict_list']]
    return plot_dict['selected_channel_names']

def check_selected_channels(selected_channel_names, x_axis, y_axis, plot_dict):
    if not x_axis in selected_channel_names:
        print "I did't find the channel that you chose with -x (or default 'Current' if you didn't select)"
        print "These are the available channels that you selected with -c (" + x_axis + "):"
        print '\n'.join(selected_channel_names)
        exit()

    if not y_axis == None:
        for selected_y in y_axis:
            if not selected_y in selected_channel_names:
                print "I did't find the channel '"+selected_y+"' that you chose with -y"
                print "These are the available channels that you selected with -c (" + selected_y + "):"
                print '\n'.join(selected_channel_names)
                exit()

def compute_min_max_avg(plot_dict, y_axis_names):

    average_name, matched_names = add_average_channel_data(plot_dict, y_axis_names)

    for i, mtbop_data in enumerate(plot_dict['mtbop_data_list']):
        channel_names = mtbop_data['channel_names']
        ch_indices = [channel_names.index(name) for name in matched_names if name in channel_names]
        add_column_to_mtbop_raw_data(mtbop_data, np.min(mtbop_data['raw_data'][:, ch_indices],axis=1), average_name+' Min')
        add_column_to_mtbop_raw_data(mtbop_data, np.max(mtbop_data['raw_data'][:, ch_indices],axis=1), average_name+' Max')
        add_column_to_mtbop_raw_data(mtbop_data, np.average(mtbop_data['raw_data'][:, ch_indices],axis=1), average_name+' Avg')

def compute_channel_deltas(plot_dict):
    added_dicts = []
    for channel in plot_dict['channel_dict_list']:
        delta_channel = dict(channel)
        delta_channel['name'] = 'Delta ' + channel['name']
        added_dicts.append(delta_channel)
        plot_dict['channel_name_dict'][delta_channel['name']] = delta_channel
        for mtbop_data in plot_dict['mtbop_data_list']:
            if channel['name'] in mtbop_data['channel_names']:
                channel_index = mtbop_data['channel_names'].index(channel['name'])
                delta_channel_data = mtbop_data['raw_data'][:, channel_index] - mtbop_data['raw_data'][0, channel_index]
                add_column_to_mtbop_raw_data(mtbop_data, delta_channel_data, delta_channel['name'])

    plot_dict['channel_dict_list'] += added_dicts


def print_plot_info(plot_dict):
    print "!!!!! ----------------------------------------------------------------!!!!!"
    print "!!!!!                            Plot Info                            !!!!!"
    print "!!!!! ----------------------------------------------------------------!!!!!"
    print "Available channel names:"
    print '\n'.join(plot_dict['selected_channel_names'])

def find_common_location(plot_dict):
    used_names = plot_dict['y_axis']
    if 'matched_names' in plot_dict and not plot_dict['matched_names'] == None: used_names = plot_dict['matched_names']
    
    print 'find common location for:', used_names
    selected_channels = [channel for channel in plot_dict['channel_dict_list'] if channel['name'] in used_names]
    location_words_list = [channel['location'].split()+[channel['longitudinal location']] for channel in selected_channels]
    first_words = location_words_list.pop()
    common_words = ' '.join(first_words)
    if len(location_words_list) != 0:
        common_words_list = []
        rest_of_words = list(set([word for word_list in location_words_list for word in word_list]))
        print 'location_words_list:', location_words_list
        print 'first_words:', first_words
        print 'rest_of_words:', rest_of_words
        for word in first_words:
            if all(word in word_list for word_list in location_words_list): 
                common_words_list.append(word)

        common_words = ' '.join(common_words_list)

    print 'common location:', common_words
    plot_dict['common location'] = common_words


def plot_data(plot_dict, args=None):
    x_axis = plot_dict['x_axis']
    y_axis_list = plot_dict['y_axis']
    if y_axis_list == None: 
        print "You didn't choose any channels on y-axis, exiting..."
        exit()

    colors = ['b','g','r','c','m','y','k','orange']
    markers = ['o', '^', 'v', '<', '>', '1', '2', '3', '4', 's', 'p', '*', 'h', '+', 'x']

    find_common_location(plot_dict)
    for j, y_axis in enumerate(y_axis_list):
        for i, mtbop_data in enumerate(plot_dict['mtbop_data_list']):
            if plot_dict['curve coloring'] == 'filewise':
                mtbop_data['color'] = colors[i%len(colors)]
                mtbop_data['marker'] = markers[i%len(markers)]
            else:
                mtbop_data['color'] = colors[j%len(colors)]
                mtbop_data['marker'] = markers[j%len(markers)]

            if x_axis == 'Current':
                detect_max_current(mtbop_data)
            mtbop_data['x_axis'] = plot_dict['channel_name_dict'][x_axis]
            mtbop_data['y_axis'] = plot_dict['channel_name_dict'][y_axis]
            channel_names = mtbop_data['channel_names']
            x_axis = mtbop_data['x_axis']['name']
            y_axis = mtbop_data['y_axis']['name']
            if x_axis in channel_names and y_axis in channel_names and not x_axis == y_axis: 
                mtbop_data['x_axis']['index']= channel_names.index(x_axis)
                mtbop_data['y_axis']['index']= channel_names.index(y_axis)
                mtbop_data['markevery'] = plot_dict['markevery']
                mtbop_data['no_markers'] = plot_dict['no_markers']
                mtbop_data['normalize x'] = plot_dict['normalize x']
                mtbop_data['plot delta'] = plot_dict['plot delta']
                mtbop_data['label type'] = plot_dict['label type']
                mtbop_data['common location'] = plot_dict['common location']
                mtbop_data['show_min_max_labels'] = plot_dict['show_min_max_labels']
                plot_mtbop_data(mtbop_data, args)

def search_channel_names_for_y_axis(plot_dict, args):
    print "search_channel_names_for_y_axis: I'm trying to search for all the channel names that contain the words given with --y-axis"
    print "search_channel_names_for_y_axis: y_axis: = ", args.y_axis
    found_channels = []
    filter_str_list = []
    if args.filter_out_any != None:
        filter_str_list = args.filter_out_any.split()
    print "search_channel_names_for_y_axis: filtering out any: ", filter_str_list
    for search_name in args.y_axis:
        search_words = search_name.split()
        for name in plot_dict['selected_channel_names']:
            if all(word in name for word in search_words):
                if not any(word in name for word in filter_str_list):
                    print "search_channel_names_for_y_axis: found channel:", name
                    found_channels.append(name)
                else:
                    print "search_channel_names_for_y_axis: found channel:", name, "but this was filtered out."

    args.y_axis = list(set(found_channels))
    if len(args.y_axis) == 0: 
        print "I didn't find any maching channels... Exiting!"
        exit()
    print "search_channel_names_for_y_axis: this is what I found:", args.y_axis

if __name__ == '__main__':
	parser = argparse.ArgumentParser(description='Plot mtbop strain data')
	parser.add_argument('paths', nargs='+', type=str)
	parser.add_argument('-i', '--info', action='store_true', default=False)
	parser.add_argument('-c', '--channels-json', nargs='?', type=str)
	parser.add_argument('-p', '--plot', action='store_true', default=False) 
	parser.add_argument('-x', '--x-axis', type=str)
	parser.add_argument('-y', '--y-axis', nargs='+', type=str)
	parser.add_argument('-s', '--plot-stress', action='store_true', default=False) 
	parser.add_argument('-o', '--override-pickle', action='store_true', default=False) 
	parser.add_argument('-m', '--markevery', type=int) 
	parser.add_argument('--no-current-squared', action='store_true', default=False) 
	parser.add_argument('--print-max-current', action='store_true', default=False) 
	parser.add_argument('--save-fig', type=str)
	parser.add_argument('-d', '--plot-delta', action='store_true', default=False) 
	parser.add_argument('--min-max-avg', nargs='+', type=str)
	parser.add_argument('--show-min-max-labels', action='store_true', default=False) 
	parser.add_argument('--normalize-x', type=str)
        parser.add_argument('--label-type', type=str)
        parser.add_argument('--curve-coloring', type=str)
        parser.add_argument('--filter-out-any', type=str)
        parser.add_argument('--set-xticks', type=str)
        parser.add_argument('--set-yticks', type=str)
        parser.add_argument('--set-xlim', type=str)
        parser.add_argument('--set-ylim', type=str)
	parser.add_argument('--grid', action='store_true', default=True) 
        parser.add_argument('-sp', '--show-plot', action='store_true', default=False) 
        parser.add_argument('-rc', '--replace-channels', action='store_true', default=False)
        parser.add_argument('--fit', action='store_true', default=False)
        parser.add_argument('--fit-range', type=str)

	args = parser.parse_args()
	paths = args.paths
	info = args.info
	channels_json = args.channels_json
        #if channels_json == None: channels_json = 'channels.json'
	x_axis = args.x_axis
	plot = args.plot
        if not args.y_axis == None: plot = True
        plot_all = False
        if args.y_axis == None and plot: plot_all = True
	plot_stress = args.plot_stress
	override_pickle = args.override_pickle
        markevery = args.markevery

        args.path_base_names = args.paths
        for FT in FILETYPES:
            args.path_base_names = [path.replace(FT, '') for path in args.path_base_names]
        if args.save_fig == None and args.y_axis != None: args.save_fig = '-'.join([name.replace(' ','_') for name in args.path_base_names]) + '-' + '-'.join([name.replace(' ','_') for name in args.y_axis]) + '.png'
        else: args.save_fig =  'plot.png'

        if x_axis == None: x_axis = 'Current'
	plot_dict = create_plot_dict(paths, channels_json, plot_stress, args=args)
        plot_dict['x_axis'] = x_axis
        plot_dict['markevery'] = markevery
        plot_dict['plot delta'] = args.plot_delta
        if plot_dict['plot delta']: compute_channel_deltas(plot_dict)
        plot_dict['normalize x'] = args.normalize_x
        if markevery == None:
            plot_dict['no_markers'] = True
        else:
            plot_dict['no_markers'] = False

        filter_out_str = args.filter_out_any
        plot_dict['filter_out_str'] = filter_out_str
        filter_plot_dict(plot_dict)

        min_max_avg = args.min_max_avg
        if not plot_dict['plot delta'] == None and plot_dict['plot delta']: 
            args.y_axis = map(lambda name: 'Delta ' + name, args.y_axis)
            if not min_max_avg == None:
                min_max_avg = map(lambda name: 'Delta ' + name, min_max_avg)

        if min_max_avg != None:
            if min_max_avg[0] == "y": min_max_avg = args.y_axis
            compute_min_max_avg(plot_dict, min_max_avg)
        plot_dict['show_min_max_labels'] = args.show_min_max_labels

        plot_dict['label type'] = args.label_type

        curve_coloring = args.curve_coloring
        if curve_coloring == None:
            plot_dict['curve coloring'] = ''
        else:
            plot_dict['curve coloring'] = curve_coloring

        selected_channel_names = get_selected_channel_names(plot_dict)
        search_channel_names_for_y_axis(plot_dict, args)

        if plot_all:
            plot_dict['y_axis'] = plot_dict['selected_channel_names']
        else:
            plot_dict['y_axis'] = args.y_axis

	if info: 
            print_plot_info(plot_dict)
            print "!!!!! ----------------------------------------------------------------!!!!!"
            print "!!!!! NOTE! I didn't plot anything because you used -i or --info flag !!!!!"
            print "!!!!! ----------------------------------------------------------------!!!!!"
            exit()

        check_selected_channels(selected_channel_names, x_axis, args.y_axis, plot_dict)

        if args.set_xticks != None:
            xticks = [float(tic) for tic in args.set_xticks.split()]
            ax.set_xticks(xticks)

        if args.set_yticks != None:
            yticks = [float(tic) for tic in args.set_yticks.split()]
            ax.set_yticks(yticks)

        if args.set_xlim!= None:
            xlim= [float(rang) for rang in args.set_xlim.split()]
            ax.set_xlim(xlim)

        if args.set_ylim!= None:
            ylim= [float(rang) for rang in args.set_ylim.split()]
            ax.set_ylim(ylim)

        ax.grid(args.grid)

        if plot or args.show_plot:
            plot_data(plot_dict, args)
            if x_axis == 'NTP Time':
                lgd = ax.legend(loc='upper center', bbox_to_anchor=(0.5,-.3), fancybox=True, shadow=True, ncol=2)
            else:
                lgd = ax.legend(loc='upper center', bbox_to_anchor=(0.5,-.1), fancybox=True, shadow=True, ncol=2)
            #ax.legend()
            #ax.show()
            autoscale_y(args)
            if args.no_thermal_compensation:
                xmin, xmax = ax.get_xlim()
                ymin, ymax = ax.get_ylim()
                print xmin, ymax
                ax.text(xmin + (xmax-xmin)/3., ymin + 2.*(ymax-ymin)/3., "No thermal compensation", style='italic', bbox={'facecolor': 'yellow', 'alpha':0.3, 'pad': 10})

            if args.show_plot:
                plt.show()
            else:
                print "Saving plot:", args.save_fig
                plt.savefig(args.save_fig, bbox_extra_artists=(lgd,), bbox_inches='tight')




