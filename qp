#!env python

import numpy as np
import matplotlib.pyplot as plt
import time
#import pandas as pd
import cPickle as pickle
import os
import codecs
import argparse
import tabulate
import json

"""
 %% Compute Stress Option 
 E_ti = 130e6/10e5/10e2 % GPa,muStrain,MPa - Warm = Cold
 v_ti = 0.30
 k_plane_ti = E_ti/(1-v_ti^2)
 E_al = 79e6/10e5/10e2
 % Exp. Values
 Nq = length(DB.Current)
 dmax = 13
    for iq = 1 : Nq
      DB.Stress.Coil.C105.Theta{iq} = k_plane_ti*(DB.Coil.C105.Theta{iq}+v_ti*DB.Coil.C105.Zeta{iq})
      DB.Stress.Coil.C106.Theta{iq} = k_plane_ti*(DB.Coil.C106.Theta{iq}+v_ti*DB.Coil.C106.Zeta{iq})
      DB.Stress.Coil.C107.Theta{iq} = k_plane_ti*(DB.Coil.C107.Theta{iq}+v_ti*DB.Coil.C107.Zeta{iq})
      DB.Stress.Coil.C007.Theta{iq} = k_plane_ti*(DB.Coil.C007.Theta{iq}+v_ti*DB.Coil.C007.Zeta{iq})
  
"""
MATERIAL_DATA = { 
		'titanium' : {
			'elastic_modulus':'130e9',
			'poisson_ratio':'0.30'
			},
		'aluminium' : {
			'elastic_modulus':'79e6',
			'poisson_ratio':'0.34'
			}
		}

def compute_stress(strain_theta, strain_z, material, axis):
	"""
	stress_z     = E/(1-v**2)*(strain_z     * v * strain_theta)
	stress_theta = E/(1-v**2)*(strain_theta * v * strain_z)
	"""
	E = float(MATERIAL_DATA[material]['elastic_modulus'])
	v = float(MATERIAL_DATA[material]['poisson_ratio'])
	if axis=='theta': 
		strain_1 = strain_theta
		strain_2 = strain_z
	elif axis=='z': 
		strain_1 = strain_z
		strain_2 = strain_theta
	return E/(1.-v**2.)*(strain_1[:] + v * strain_2[:])

def compute_stress_simple(strain, material):
	"""
	stress     = E*strain
	"""
	E = float(MATERIAL_DATA[material]['elastic_modulus'])
	return E * strain[:]


def find_strain_data(mtbop_data, strain_name):
	basename = strain_name[0:-1]
	if strain_name[-1] == 'T': 
		name_theta = strain_name
		name_z = basename + 'Z'
		axis = 'theta'
	elif strain_name[-1] == 'Z':
		name_theta = basename + 'T'
		name_z = strain_name
		axis = 'z'
	else: 
		print "Warning: find_strain_data failed for ", strain_name
	
	if 'SH' in basename: material = 'aluminium'
	elif 'R' in basename: material = 'aluminium'
	elif 'CO' in basename: material = 'titanium'
	else: print "Warning: find_strain_data failed"

	raw_data = mtbop_data['raw_data']
	strain_theta = raw_data[:, find_channel_index(mtbop_data['channel_names'], name_theta)]
	strain_z =     raw_data[:, find_channel_index(mtbop_data['channel_names'], name_z)]

	return strain_theta, strain_z, material, axis

def timeit(func):
	def wrapper(*args, **kwargs):
		time_start = time.time()
		o=func(*args, **kwargs)
		print 'timeit: ', func.__name__, ':{0:0.2f}s'.format(time.time()-time_start)
		return o
	return wrapper

def tol_cols(array):
	return np.array([np.max(col)-np.min(col) for col in array.transpose()])

@timeit
def detect_max_current(mtbop_data):
	raw_data = mtbop_data['raw_data']
	current_array = raw_data[:, find_channel_index(mtbop_data['channel_names'], 'Current')]
	grad_array = np.gradient(current_array)
	qinx = np.argmin(grad_array)
	qinx = np.argmax(current_array)
	mtbop_data['max_current_index'] = qinx
	mtbop_data['max_current'] = current_array[qinx]
	mtbop_data['max_current_grad'] = grad_array[qinx]
	print "mtbop_data['max_current_index']", mtbop_data['max_current_index']
	print "mtbop_data['max_current_grad']", mtbop_data['max_current_grad']
	print "mtbop_data['max_current']", mtbop_data['max_current']

def detect_first_values(mtbop_data):
	raw_data = mtbop_data['raw_data']
	initial_values = None
	for i, row in enumerate(raw_data):
		if np.all(filtered_array[i]==0): 
			initial_values = raw_data[i]
			break
	mtbop_data['initial_values'] = initial_values
	

@timeit
def dist_filter(array, abs_dist, filtered_array, turn_on=False):
	"""
	Filter Numpy array column wise. Collect first point of the array and then every point for which the 
	column wise value deviates a distance from the last collected point.
	
	Parameters
	__________
	array : numpy.ndarray
		data array to be filtered
	abs_tol : numpy.ndarray
		column wise distances for the filtering

	Returns
	-------
	filtered_array : numpy.ndarray (bool)
		filtered out elements
	"""
	abs_dist = np.array(abs_dist)
	filtered_array_new = []
	last_mark=None
	for i, row in enumerate(array):
		#if np.any(filtered_array[i] > 0):
			#filtered_row[:] = True
		if last_mark is None or not turn_on:
			last_mark=row
			filtered_row = np.array(np.absolute(row) != np.absolute(row))
		else:
			filtered_row = np.absolute(row-last_mark) < abs_dist
			last_mark = filtered_row*last_mark+(np.logical_not(filtered_row))*row

		filtered_array_new.append(filtered_row)
	return np.array(filtered_array_new)

def filter_indices_after_index(mtbop_data):
	filtered_array = mtbop_data['filtered_array']
	index = mtbop_data['max_current_index']
	filtered_array[index:,:] = 1
	
def index_union(filtered_array, selected_axes_dict):
	inx_sum = np.sum(filtered_array[:,selected_axes_dict], axis=1)
	inx_union = np.where(inx_sum == 0)[0]
	return inx_union

def index_cut(filtered_array, selected_axes_dict):
	inx_product = np.prod(filtered_array[:,selected_axes_dict], axis=1)
	inx_cut = np.where(inx_product == 0)[0]
	return inx_cut

@timeit
def select_mtbop_data(mtbop_data, selected_axes):
	filtered_array = mtbop_data['filtered_array']
	initial_values = mtbop_data['initial_values']
	raw_data = mtbop_data['raw_data']
	inxs = index_union(filtered_array, selected_axes)
	selected_data = raw_data[:,selected_axes][inxs,:]
	if mtbop_data['plot_delta']:
		selected_data[:,:] -= initial_values[[selected_axes]]
	return selected_data

@timeit
def plot_mtbop_data(mtbop_data):
        max_current_index = mtbop_data['max_current_index']
	raw_data = mtbop_data['raw_data']
        x_axis_dict = mtbop_data['x_axis']
        y_axis_dict = mtbop_data['y_axis']

        ax_dicts = [x_axis_dict, y_axis_dict]
        for ax_dict in ax_dicts:
            ax_dict['raw_data'] = raw_data[:max_current_index,ax_dict['index']]
            if ax_dict['name'].lower() == 'current':
                ax_dict['raw_data'] = ax_dict['raw_data']**2.
                ax_dict['label'] = ax_dict['name'] + '(' + ax_dict['unit'] + '$^2$)'
            else:
                ax_dict['label'] = ax_dict['direction'] + ' ' + ax_dict['physical_quantity'] + '(' + ax_dict['unit'] + ')'

        plt.xlabel(x_axis_dict['label'])
        plt.ylabel(y_axis_dict['label'])
        if mtbop_data['no_markers']:
            plt.plot(x_axis_dict['raw_data'],y_axis_dict['raw_data'], mtbop_data['color']+'-')
        else:
            plt.plot(x_axis_dict['raw_data'],y_axis_dict['raw_data'], mtbop_data['color']+mtbop_data['marker']+'-', markevery=mtbop_data['markevery'])

@timeit
def plot_selected_list(plot_dict):
        mtbop_data_list = plot_dict['mtbop_data_list']
	for mtbop_data in mtbop_data_list:
		plot_selected(mtbop_data)

def plot_raw_current(mtbop_data):
	raw_data = mtbop_data['raw_data']
	current_index = mtbop_data['current_index']
	plt.plot(raw_data[:, current_index], label=mtbop_data['filepath'])

@timeit
def plot_selected_list_raw_current(mtbop_data_list):
	for mtbop_data in mtbop_data_list:
		plot_raw_current(mtbop_data)
	plt.legend()

@timeit
def load_mtbop_data(filepath, override_pickle=False, header_lines=38):
	"""
	Loads mtbop data from txt file.
	
	Parameters
	__________
	filepath : string
		path of the mtbop data file
	header_lines : int
		number of header lines in mtbop file
	
	Returns
	-------
	mtbop_data : json?
		{
		 'filepath' = string,
		 channel_names = [string, .., string],
		 channel_units = [string, .., string],
		 raw_data = numpy.ndarray}
	"""
	basename = os.path.splitext(filepath)[0]
	pickle_path = basename + '.pickle'
	if os.path.isfile(pickle_path) and not override_pickle:
		print "Found a pickle:", pickle_path, "for", filepath, "using that instead."
		return cpickle_load(pickle_path)

	mtbop_data = {}
	with codecs.open(basename + '.txt') as f:
		head = [next(f).decode('utf-8', 'ignore') for x in xrange(header_lines)]
	channel_names = head[8].strip('\r\n').split('\t')
	channel_names = [name.split()[0].replace('_cryo','') for name in channel_names]
	channel_units = head[9].strip('\r\n').split('\t')
	#raw_data_df = pd.read_csv(filepath, sep = '\t', skiprows=header_lines, names=channel_names)

	with codecs.open(filepath) as f:
		raw_data = np.loadtxt(f, skiprows=header_lines)
	mtbop_data['filepath'] = filepath
	mtbop_data['channel_names'] = channel_names
	mtbop_data['channel_units'] = channel_units
	#mtbop_data['raw_data_df'] = raw_data_df
	#mtbop_data['raw_data'] = raw_data_df.values
	mtbop_data['raw_data'] = raw_data
	#mtbop_data['filtered_array'] = np.zeros(np.shape(raw_data))
	#mtbop_data['channel_tolerance'] = tol_cols(mtbop_data['raw_data'])
	#detect_max_current(mtbop_data)

	#filter_indices_after_index(mtbop_data)
	#detect_first_values(mtbop_data)
	
	cpickle_dump(mtbop_data, pickle_path)
	return mtbop_data

def load_mtbop_list(filepath_list, override_pickle=False, header_lines=38):
	mtbop_data_list = []
	for filepath in filepath_list:
		mtbop_data = load_mtbop_data(filepath, override_pickle)
		mtbop_data_list.append(mtbop_data)
	return mtbop_data_list

def find_channel_index(channel_names, channel_name):
	return channel_names.index(channel_name)

def find_axes(mtbop_data):
	channel_names = mtbop_data['channel_names']
	channel_units = mtbop_data['channel_units']
	mtbop_data['current_index'] = channel_names.index('Current')
	axes_list = []
	for pair in name_pairs:
		if pair[0] in channel_names and pair[1] in channel_names: 
			first = channel_names.index(pair[0])
			second = channel_names.index(pair[1])
			axes = {'selected_axes': (first,second)}
			if pair[0].lower() == 'current':
				axes['0 scaling']='current'
			else: 
				axes['0 scaling']=''
			if pair[1].lower() == 'current':
				axes['1 scaling']='current'
			else: 
				axes['1 scaling']=''
			axes['0 name'] = pair[0]
			axes['1 name'] = pair[1]
			axes['0 unit'] = channel_units[first]
			#axes['1 unit'] = channel_units[second]
			axes_list.append(axes)
	return axes_list

@timeit
def test_pandas_load_data(filepath, header_lines=38):
	raw_data = pd.read_csv(filepath, sep = '\t', skiprows=header_lines,usecols=range(21))
	print raw_data.values[2]

@timeit
def test_numpy_load_data(filepath, header_lines=38):
	raw_data = np.loadtxt(filepath, skiprows=header_lines)
	print raw_data[2]

def test_load_data():
	filepath = 'Data/test/01QuenchDC_161013_16236.txt'
	test_pandas_load_data(filepath)
	test_numpy_load_data(filepath)

@timeit
def test_cpickle_dump():
	filepath = 'Data/test/01QuenchDC_161013_16236.txt'
	mtbop_data = load_mtbop_data(filepath)
	with open('test.pickle', 'wb') as handle:
		pickle.dump(mtbop_data, handle, protocol=pickle.HIGHEST_PROTOCOL)
@timeit
def cpickle_dump(data, pickle_path):
	with open(pickle_path, 'wb') as handle:
		pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)
	
@timeit
def cpickle_load(pickle_path):
	with open(pickle_path, 'rb') as handle:
		mtbop_data = pickle.load(handle)
	return mtbop_data

def print_max_current(mtbop_data):
	print mtbop_data['filepath'], mtbop_data['max_current']

def make_info_table(mtbop_data_list):
	info_table = [['File path', 'Max Current']]
	for mtbop_data in mtbop_data_list:
		info_table.append([mtbop_data['filepath'], mtbop_data['max_current']])
	return info_table

def test_plot_selected():
	#use_dist_filter = False
	#nof_points = 1e4
	filepath = 'Data/test/01QuenchDC_161013_16236.txt'
	#filepath = 'Data/test/02QuenchDC_161013_18055.txt'
	selected_channel_names = [('Current','CO105Z_cryo'), ('Current','CO105T_cryo')]
	#selected_channel_names = [('Current','CO105T_cryo')]
	plot_delta = True
	#selected_channel_names = [('CO105T_cryo','Current')]
	#selected_channel_names = [('Current','SHTT_cryo')]
	#selected_channel_names = [('CO105T_cryo','SHTT_cryo')]

	mtbop_data = load_mtbop_data(filepath)
	mtbop_data['selected_channel_names'] = selected_channel_names
	mtbop_data['selected_axes_dict'] = find_axes(mtbop_data)
	mtbop_data['plot_delta'] = plot_delta

	#mtbop_data['filter_approx_points'] = nof_points
	#filtered_array = dist_filter(raw_data, tol/nof_points, filtered_array, turn_on=use_dist_filter)

	plot_selected(mtbop_data)

	plt.show()

def test_plot_selected_list():
	#datadir = 'Data/MQXFS4' 
	#datadir = 'Data/HCMQXFS004-CR000001' 
	#filepath_list = [datadir + '/' + f for f in os.listdir(datadir) if ".txt" in f]
	max_current_low_limit = 15
	
	#filepath_list = ['Data/test/01QuenchDC_161013_16236.txt', 
		         #'Data/test/02QuenchDC_161013_18055.txt']
	#selected_channel_names = [('CO105T_cryo','Current')]

	filepath_list = ['Data/HCMQXFS004-CR000001/180704_12_15_23_Quench.txt', 
                         'Data/HCMQXFS004-CR000001/180709_14_40_50_Quench.txt', 
                         'Data/HCMQXFS004-CR000001/180730_18_07_11_Quench.txt']

	print filepath_list

	mtbop_data_list = []
	selected_channel_names = [('Current','CO109T')]
	plot_delta = True
	for filepath in filepath_list:
		mtbop_data = load_mtbop_data(filepath)
		if mtbop_data['max_current'] > max_current_low_limit:
			mtbop_data_list.append(mtbop_data)
			mtbop_data = mtbop_data_list[-1]
			mtbop_data['selected_channel_names'] = selected_channel_names
			mtbop_data['selected_axes_dict'] = find_axes(mtbop_data)
			mtbop_data['plot_delta'] = plot_delta
			print_max_current(mtbop_data)

	plot_selected_list(mtbop_data_list)
	#plot_selected_list_raw_current(mtbop_data_list)

	plt.show()

def plot_selected_files(filepath_list, selected_channel_names):
	max_current_low_limit = 15

	mtbop_data_list = []
	plot_delta = True
	for filepath in filepath_list:
		mtbop_data = load_mtbop_data(filepath)
		if mtbop_data['max_current'] > max_current_low_limit:
			mtbop_data_list.append(mtbop_data)
			mtbop_data = mtbop_data_list[-1]
			mtbop_data['selected_channel_names'] = selected_channel_names
			mtbop_data['selected_axes_dict'] = find_axes(mtbop_data)
			mtbop_data['plot_delta'] = plot_delta
			print_max_current(mtbop_data)

	plot_selected_list(mtbop_data_list)
	#plot_selected_list_raw_current(mtbop_data_list)

	plt.show()

def testing():
	test_plot_selected()
	#test_plot_selected_list()
	#test_load_data()
	#test_cpickle_dump()
	#cpickle_load('test.pickle')


def print_mtbop_info(filepaths):
	info_table = make_info_table(mtbop_data_list)
	print tabulate.tabulate(info_table, headers="firstrow")

def find_channel_names(mtbop_data_list):
	channel_names_list = []
	for mtbop_data in mtbop_data_list:
		channel_names_list += mtbop_data['channel_names']
	return list(set(channel_names_list))
	
def find_files(paths):
	filepaths=[]
	for path in paths:
		if os.path.isdir(path):
			filepaths += [path + '/' + f for f in os.listdir(path) if ".txt" in f]
		elif os.path.isfile(path) and ".txt" in f:
			filepaths.append(path)
	return filepaths

def create_channel_data(mtbop_data_list):
	channel_names = find_channel_names(mtbop_data_list)
	channel_dict_list = [] 
	for channel_name in channel_names:
		channel_dict_list.append({})
		channel_dict = channel_dict_list[-1]
		channel_dict['name'] = channel_name
		if channel_name[0:2] == 'SH':
			shell_location = ''
			if channel_name[2] == 'R': shell_location = 'Right'
			elif channel_name[2] == 'L': shell_location = 'Left'
			elif channel_name[2] == 'T': shell_location = 'Top'
			elif channel_name[2] == 'B': shell_location = 'Bottom'
			channel_dict['location'] = 'Shell ' + shell_location
			channel_dict['physical_quantity'] = 'Strain'
			channel_dict['unit'] = 'um/um'
		elif channel_name[0] == 'R': 
			channel_dict['location'] = 'Rod ' + channel_name[1]
			channel_dict['physical_quantity'] = 'Strain'
			channel_dict['unit'] = 'um/um'
		elif channel_name[0:2] == 'CO':
			channel_dict['location'] = 'Coil ' + channel_name[2:5]
			channel_dict['physical_quantity'] = 'Strain'
			channel_dict['unit'] = 'um/um'
		elif channel_name == 'Current':
			channel_dict['physical_quantity'] = 'Current'
			channel_dict['location'] = 'None'
			channel_dict['unit'] = 'A'
		else:
			channel_dict['location'] = channel_name 
			channel_dict['physical_quantity'] = 'None'
			channel_dict['unit'] = 'None'
		if channel_name[-1] == 'Z':
			channel_dict['direction'] = 'Longitudinal'
		elif channel_name[-1] == 'T':
			channel_dict['direction'] = 'Azimuthal'
		else:
			channel_dict['direction'] = 'None'

                channel_dict['longname'] = channel_longname(channel_dict)

	print "Writing channels.json"
	with open('channels.json', 'w') as outfile:
		json.dump(channel_dict_list, outfile, indent=4)
	
	return channel_dict_list

def add_stress_channel_data(plot_dict):
    added_dicts = []
    channel_dict_list = plot_dict['channel_dict_list']
    for channel_dict in channel_dict_list:
        if channel_dict['physical_quantity'] == 'Strain':
            added_dicts.append(dict(channel_dict))
            added_dict = added_dicts[-1]
            added_dict['physical_quantity'] = 'Stress'
            added_dict['long_name'] = channel_longname(channel_dict)
            added_dict['name'] = added_dict['long_name'] 
    plot_dict['channel_dict_list'] += added_dicts

def channel_longname(channel_dict):
    return channel_dict['location'] + ' ' + channel_dict['direction'] + ' ' + channel_dict['physical_quantity']


def find_channels_from_dict(channel_dict_list, location, physical_quantity, direction):
	channel_dict_sub = []
	for channel_dict in channel_dict_list: 
		if channel_dict['location'] == location and channel_dict['physical_quantity'] == physical_quantity and channel_dict['direction'] == direction:
			   channel_dict_sub.append(channel_dict)
	return channel_dict_sub


def read_channels_json(channels_json_file_path):
	with open(channels_json_file_path, 'r') as f:
		data_json = json.load(f)
	return data_json

def double_array_columns_with_zeros(array):
	size1, size2 = np.shape(array)
	new_array = np.zeros((size1, 2*size2))
	new_array[:,0:size2] = array
	return new_array

def double_vector_with_zeros(vector):
	size = np.size(vector)
	new_vector = np.zeros(2*size)
	new_vector[0:size] = vector
	vector = new_vector

def compute_stresses(mtbop_data, channel_dicts):
	print "Computing stresses for:", mtbop_data['filepath']
	raw_data = mtbop_data['raw_data']
	size1, size2 = np.shape(raw_data)
	mtbop_data['raw_data'] = double_array_columns_with_zeros(raw_data)
	raw_data = mtbop_data['raw_data']

	mtbop_data['filtered_array'] = double_array_columns_with_zeros(mtbop_data['filtered_array'])
	print np.shape(mtbop_data['initial_values'])
	mtbop_data['initial_values'] = double_vector_with_zeros(mtbop_data['initial_values'])
	print np.shape(mtbop_data['initial_values'])

	locations = list(set([channel_dict['location'] for channel_dict in channel_dicts]))
	computed_dicts = []

	channel_count = 0
	for location in locations:
		if not location == 'None':
			print "location: ", location
			azimuthal_dicts = find_channels_from_dict(channel_dicts, location, 'Strain', 'Azimuthal')
			if len(azimuthal_dicts) == 1: azimuthal_dict = azimuthal_dicts[0]
			else: azimuthal_dict = None
			longitudinal_dicts = find_channels_from_dict(channel_dicts, location, 'Strain', 'Longitudinal')
			if len(longitudinal_dicts) == 1: longitudinal_dict = longitudinal_dicts[0]
			else: 
				print "Error: longitudinal of the location was not found!"
				exit()

			longitudinal_name = longitudinal_dict['name']
			longitudinal_index = find_channel_index(mtbop_data['channel_names'], longitudinal_name)

			if 'Shell' in longitudinal_dict['location']: material = 'aluminium'
			elif 'Rod' in longitudinal_dict['location']: material = 'aluminium'
			elif 'Coil' in longitudinal_dict['location']: material = 'titanium'

			print channel_count

			if not azimuthal_dict == None:
				azimuthal_name = azimuthal_dict['name']
				azimuthal_index = find_channel_index(mtbop_data['channel_names'], azimuthal_name)
				raw_data[:, size2+channel_count] = compute_stress(raw_data[:,azimuthal_index], raw_data[:,longitudinal_index], material, 'theta')
				channel_count += 1
				computed_dicts.append({})
				channel_name = location + ' Azimuthal Stress'
				computed_dicts[-1]['name'] = channel_name
				computed_dicts[-1]['location'] = location
				computed_dicts[-1]['physical_quantity'] = 'Stress'
				computed_dicts[-1]['direction'] = 'Azimuthal'
				mtbop_data['channel_names'].append(channel_name)

				raw_data[:, size2+channel_count] = compute_stress(raw_data[:,azimuthal_index], raw_data[:,longitudinal_index], material, 'z')
				channel_count += 1
				computed_dicts.append({})
				channel_name = location + ' Longitudinal Stress'
				computed_dicts[-1]['name'] = channel_name
				computed_dicts[-1]['location'] = location
				computed_dicts[-1]['physical_quantity'] = 'Stress'
				computed_dicts[-1]['direction'] = 'Longitudinal'
				mtbop_data['channel_names'].append(channel_name)
			else:
				raw_data[:, size2+channel_count] = compute_stress_simple(raw_data[:,longitudinal_index], material)
				channel_count += 1
				computed_dicts.append({})
				channel_name = location + ' Longitudinal Stress'
				computed_dicts[-1]['name'] = channel_name
				computed_dicts[-1]['location'] = location
				computed_dicts[-1]['physical_quantity'] = 'Stress'
				computed_dicts[-1]['direction'] = 'Longitudinal'
				mtbop_data['channel_names'].append(channel_name)

def create_channel_name_dict(channel_dict_list):
	channel_name_dict = {}
	for channel_dict in channel_dict_list:
		channel_name_dict[channel_dict['name']]=channel_dict
	return channel_name_dict

def create_plot_dict(paths, channels_json, plot_stress=False):
	plot_dict = {}
	plot_dict['paths'] = paths
	plot_dict['filepaths'] = find_files(paths)
	plot_dict['mtbop_data_list'] = load_mtbop_list(plot_dict['filepaths'], override_pickle)
	plot_dict['plot_stress'] = plot_stress

	if not channels_json == None: 
		plot_dict['channel_dict_list'] = read_channels_json(channels_json)
	else:
		plot_dict['channel_dict_list'] = create_channel_data(plot_dict['mtbop_data_list'])

        if plot_stress:
            add_stress_channel_data(plot_dict)
            #compute_stresses(mtbop_data, channel_dicts)

	plot_dict['channel_name_dict'] = create_channel_name_dict(plot_dict['channel_dict_list'])

	return plot_dict 

def get_selected_channel_names(plot_dict):
    plot_dict['selected_channel_names'] = [channel_dict['name'] for channel_dict in plot_dict['channel_dict_list']]
    return plot_dict['selected_channel_names']

def check_selected_channels(selected_channel_names, x_axis, y_axis):
    if not x_axis in selected_channel_names:
        print "I did't find the channel that you chose with -x (or default 'Current' if you didn't select)"
        print "These are the available channels that you selected with -c (" + channels_json + "):"
        print '\n'.join(selected_channel_names)
        exit()

    if not y_axis == None:
        for selected_y in y_axis:
            if not selected_y in selected_channel_names:
                print "I did't find the channel", selected_y, "that you chose with -y"
                print "These are the available channels that you selected with -c (" + channels_json + "):"
                print '\n'.join(selected_channel_names)
                exit()

def print_plot_info(plot_dict):
    print "Plot info:"
    print "Selected channel names:"
    print '\n'.join(plot_dict['selected_channel_names'])

def plot_data(plot_dict):
    x_axis = plot_dict['x_axis']
    y_axis_list = plot_dict['y_axis']
    if y_axis_list == None: 
        print "You didn't choose any channels on y-axis, exiting..."
        exit()

    colors = ['b','g','r','c','m','y','k']
    markers = ['o', '^', 'v', '<', '>', '1', '2', '3', '4', 's', 'p', '*', 'h', '+', 'x']

    for j, y_axis in enumerate(y_axis_list):
        for i, mtbop_data in enumerate(plot_dict['mtbop_data_list']):
            mtbop_data['color'] = colors[i%len(colors)]
            mtbop_data['marker'] = markers[j%len(markers)]
            detect_max_current(mtbop_data)
            mtbop_data['x_axis'] = plot_dict['channel_name_dict'][x_axis]
            mtbop_data['y_axis'] = plot_dict['channel_name_dict'][y_axis]
            channel_names = mtbop_data['channel_names']
            x_axis = mtbop_data['x_axis']['name']
            y_axis = mtbop_data['y_axis']['name']
            if x_axis in channel_names and y_axis in channel_names: 
                mtbop_data['x_axis']['index']= channel_names.index(x_axis)
                mtbop_data['y_axis']['index']= channel_names.index(y_axis)
                mtbop_data['markevery'] = plot_dict['markevery']
                mtbop_data['no_markers'] = plot_dict['no_markers']
                plot_mtbop_data(mtbop_data)
 
if __name__ == '__main__':
	parser = argparse.ArgumentParser(description='Plot mtbop strain data')
	parser.add_argument('paths', nargs='+', type=str)
	parser.add_argument('-i', '--info', action='store_true', default=False)
	parser.add_argument('-c', '--channels-json', nargs='?', type=str)
	parser.add_argument('-p', '--plot', action='store_true', default=False) 
	parser.add_argument('-x', '--x-axis', type=str)
	parser.add_argument('-y', '--y-axis', nargs='+', type=str)
	parser.add_argument('-s', '--plot-stress', action='store_true', default=False) 
	parser.add_argument('-o', '--override-pickle', action='store_true', default=False) 
	parser.add_argument('-m', '--markevery', type=int) 

	args = parser.parse_args()
	paths = args.paths
	info = args.info
	channels_json = args.channels_json
        if channels_json == None: channels_json = 'channels.json'
	plot = args.plot
	x_axis = args.x_axis
	y_axis = args.y_axis
	plot_stress = args.plot_stress
	override_pickle = args.override_pickle
        markevery = args.markevery

        if x_axis == None: x_axis = 'Current'
	plot_dict = create_plot_dict(paths, channels_json, plot_stress)
        plot_dict['x_axis'] = x_axis
        plot_dict['y_axis'] = y_axis
        plot_dict['markevery'] = markevery
        if markevery == None:
            plot_dict['no_markers'] = True
        else:
            plot_dict['no_markers'] = False

        selected_channel_names = get_selected_channel_names(plot_dict)

	if info: 
            print_plot_info(plot_dict)
            exit()

        check_selected_channels(selected_channel_names, x_axis, y_axis)


	if plot:
            plot_data(plot_dict)
            plt.show()



